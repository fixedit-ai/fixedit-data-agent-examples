# Metadata Input Configuration for Analytics Scene Description
#
# This configuration uses Telegraf's execd input plugin to continuously
# consume analytics metadata from either the camera's internal message broker
# or a sample data file for testing.
#
# Key Features:
# - Runs the metadata consumer script continuously (not on intervals)
# - Processes JSON messages from the camera's analytics stream
# - Can be overridden to use mock data for testing
# - Handles real-time scene description data
#
# Environment Variables:
# - HELPER_FILES_DIR: Directory containing project files (required)
# - CONSUMER_SCRIPT: Path to consumer script (defaults to axis_metadata_consumer.sh)
# - SAMPLE_FILE: Path to sample data file (required when using sample_data_feeder.sh)
#
# Technical Details:
# - execd plugin runs the command continuously and reads stdout stream
# - Expects one JSON message per line from the script
# - Parses each line as a separate JSON object
# - No signal handling (script runs until Telegraf stops)

[[inputs.execd]]
  # Command to execute - uses CONSUMER_SCRIPT if set, otherwise defaults to live camera script
  # Default: axis_metadata_consumer.sh (live camera)
  # Override: Set CONSUMER_SCRIPT to use different script (e.g., test_files/sample_data_feeder.sh)
  command = [
    "${HELPER_FILES_DIR}/${CONSUMER_SCRIPT:-axis_scene_detection_consumer.sh}"
  ]

  # No signal handling - let the script run continuously
  # The script will keep running and outputting JSON until Telegraf stops
  signal = "none"

  # Parse each line of output as JSON format
  # Each line from the script should contain one complete JSON object
  data_format = "json"

  # Override the metric name for clarity in MQTT topics
  name_override = "detection_frame"

  # String fields that should be preserved as strings during JSON parsing
  json_string_fields = ["timestamp", "track_id", "object_type", "frame"]

# This processor sets the metric time from the timestamp field for all detection_frame metrics.
# This ensures all downstream metrics use the detection's timestamp instead of the processing time.
#
# Input: detection_frame metrics from input
# Output: Same metrics with metric.time set from timestamp field

[[processors.starlark]]
  namepass = ["detection_frame"]

  source = '''
load("time.star", "time")

def utc_string_to_epoch_nanoseconds(s):
    # Returns nanoseconds since Unix epoch (UTC).
    # Accepts RFC3339/RFC3339Nano strings like "2024-01-15T14:30:45.123456Z"
    if s == None or type(s) != type(""):
        return 0

    # Use catch() so a bad timestamp doesn't kill the script and drop metrics
    err = catch(lambda: time.parse_time(s))
    if err != None:
        return 0

    t = time.parse_time(s)  # defaults: RFC3339 + UTC
    # Telegraf time values are nanoseconds since epoch
    return t.unix_nano

def apply(metric):
    # Extract timestamp from metric fields
    timestamp = metric.fields.get("timestamp")
    if timestamp != None:
        # Convert timestamp string to nanoseconds since epoch,
        # since that is what metric.time expects
        timestamp_nanoseconds = utc_string_to_epoch_nanoseconds(timestamp)

        if timestamp_nanoseconds > 0:
            metric.time = timestamp_nanoseconds

    # Return the metric with updated time
    return metric
'''
